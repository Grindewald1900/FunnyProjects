{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "import requests\n",
    "import json\n",
    "import ssl\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start...\n",
      "92\n",
      "93\n",
      "['November 25, 2020', 'November 18, 2020', 'November\\xa05,\\xa02020', 'October\\xa014,\\xa02020', 'September\\xa030,\\xa02020', 'September\\xa016,\\xa02020', 'September\\xa02,\\xa02020', 'August\\xa020,\\xa02020', 'August\\xa019,\\xa02020', 'August\\xa06,\\xa02020', 'August\\xa05,\\xa02020', 'July\\xa023,\\xa02020', 'July\\xa022,\\xa02020', 'July\\xa08,\\xa02020', 'June\\xa025,\\xa02020', 'June\\xa024,\\xa02020', 'June\\xa011,\\xa02020', 'June\\xa010,\\xa02020', 'May\\xa028,\\xa02020', 'May\\xa027,\\xa02020', 'May\\xa014,\\xa02020', 'May\\xa013,\\xa02020', 'April\\xa030,\\xa02020', 'April\\xa029,\\xa02020', 'April\\xa016,\\xa02020', 'April\\xa015,\\xa02020', 'April\\xa09,\\xa02020', 'April\\xa09,\\xa02020', 'March\\xa023,\\xa02020', 'March\\xa018,\\xa02020', 'March\\xa04,\\xa02020', 'February 19, 2020', 'February 5, 2020', 'January 22, 2020', 'January 8, 2020', 'December 19, 2019', 'December 11, 2019', 'November 27, 2019', 'November 13, 2019', 'October 30, 2019', 'October 16, 2019', 'October 2, 2019', 'September 18, 2019', 'September 4, 2019', 'August 20, 2019', 'August 12, 2019', 'July 24, 2019', 'July 10, 2019', 'June 26, 2019', 'June 12, 2019', 'May 29, 2019', 'May 15, 2019', 'May\\xa01, 2019', 'April 17, 2019', 'April 3, 2019', 'March 20, 2019', 'March 6, 2019', 'February 20, 2019', 'January 30, 2019', 'January 23, 2019', 'January 9, 2019', 'December 19, 2018', 'December 12, 2018', 'November 28, 2018', 'November 14, 2018', 'October 29, 2018', 'October 15, 2018', 'October 3, 2018', 'September 24, 2018', 'eptember 19, 2018', 'eptember 5, 2018', 'ugust 22, 2018', 'ugust 8, 2018', 'uly 25, 2018', 'uly 11, 2018', 'une 25, 2018', 'une\\xa013, 2018', 'ay 30, 2018', 'ay\\xa023, 2018', 'ay\\xa09, 2018', 'pril\\xa025, 2018', 'pril\\xa011, 2018', 'arch\\xa026, 2018', 'arch\\xa014, 2018', 'ebruary 21, 2018', 'ebruary 7, 2018', 'anuary 24, 2018', 'anuary 10, 2018', 'ecember 20, 2017', 'ecember 6, 2017', 'ovember\\xa015, 2017', 'ovember\\xa08 2017']\n",
      "['469', '472', '478', '471', '471', '472', '475', '454', '771', '415', '476', '445', '687', '478', '431', '696', '437', '743', '440', '757', '447', '718', '452', '692', '455', '808', '464', '698', '467', '720', '471', '470', '472', '471', '473', '469', '472', '471', '472', '475', '357', '464', '462', '463', '457', '466', '459', '460', '462', '465', '470', '332', '450', '451', '451', '452', '454', '457', '438', '443', '449', '439', '445', '445', '449', '442', '440', '445', '284', '441', '440', '440', '440', '441', '442', '442', '451', '288', '902', '440', '441', '441', '444', '446', '456', '442', '442', '444', '446', '446', '452', '439', '458']\n",
      "End...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TYPE_1 = \"No program specified\"\n",
    "TYPE_2 = \"Canadian Experience Class\"\n",
    "TYPE_3 = \"Provincial Nominee Class\"\n",
    "TYPE_4 = \"Federal Skilled Trades\"\n",
    "listType = [TYPE_1, TYPE_2, TYPE_3, TYPE_4]\n",
    "listDate = list()\n",
    "listCount = list()\n",
    "url = \"https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/submit-profile/rounds-invitations/results-previous.html\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "paras = soup.find_all('p')\n",
    "date = soup.find_all('h3')\n",
    "print(\"Start...\")\n",
    "\n",
    "for item in date:\n",
    "    if re.findall(\"[0-9]*\", item.get_text()[:5])[1] != \"\":\n",
    "        if int(re.findall(\"[0-9]*\", item.get_text()[:5])[1]) > 76:\n",
    "            listDate.append(item.get_text()[7:])\n",
    "            \n",
    "for item in paras:\n",
    "    if \"lowest-ranked\" in item.get_text():\n",
    "        listCount.append(item.get_text()[-3:])\n",
    "        \n",
    "print(len(listDate))\n",
    "print(len(listCount))\n",
    "print(listDate)\n",
    "print(listCount)\n",
    "print(\"End...\")\n",
    "# print(soup.prettify())\n",
    "\n",
    "# uh = urllib.request.urlopen(url, context=ctx)\n",
    "# data = uh.read().decode().strip()\n",
    "# print(data)\n",
    "# result = re.findall(\"^specified.*p$\",data)\n",
    "# print(result)\n",
    "# print('Retrieved', len(data), 'characters')\n",
    "\n",
    "# try:\n",
    "#     js = json.loads(data)\n",
    "# except:\n",
    "#     js = None\n",
    "\n",
    "# if not js or 'status' not in js or js['status'] != 'OK':\n",
    "#     print('==== Failure To Retrieve ====')\n",
    "#     print(data)\n",
    "#     continue\n",
    "\n",
    "# print(json.dumps(js, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
